{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annual Surface Temperature and Land Cover Analysis Report\n",
    "\n",
    "## Introduction\n",
    "\n",
    "<p>Climate change is the most critical issue in contemporary times at a global level. Surface temperature change and land cover change are the two main facets of climate change. This report attempts to present a detailed analysis regarding the role of land cover in regulating the global climate and changes in surface temperature. We are going to set up an automated data pipeline that cleans, processes, and analyzes these datasets for meaningful insights using the data goaltending from the Food and Agriculture Organization Corporate Statistical Database and NASA Goddard Institute for Space Studies.</p>\n",
    "\n",
    "## Used Data\n",
    "\n",
    "The analysis utilizes two primary datasets:\n",
    "\n",
    "### Annual Surface Temperature Change:\n",
    "- **Source**: FAOSTAT, based on NASA GISS data.\n",
    "- **Period**: 1961-2021\n",
    "- **Purpose**: To analyze global temperature changes using a 1951-1980 baseline.\n",
    "\n",
    "### Land Cover and Land Cover Altering Indicator:\n",
    "- **Source**: FAOSTAT\n",
    "- **Period**: 1992-2018\n",
    "- **Purpose**: To understand the impact of different types of land cover on climate regulation and carbon sequestration.\n",
    "\n",
    "## Data License\n",
    "\n",
    "The datasets are used under the Copernicus Programme, which grants everybody free, non-exclusive, and perpetual access for lawful purposes, including reproduction and distribution. Proper attribution is given to the Copernicus Programme, ensuring compliance with their licensing terms.\n",
    "\n",
    "## Analysis\n",
    "\n",
    "### Data Pipeline Overview\n",
    "The data pipeline implemented for this project includes the following steps:\n",
    "\n",
    "1. **Data Acquisition**: Fetching CSV files from provided URLs.\n",
    "2. **Data Cleaning**: Removing missing values to ensure data quality.\n",
    "3. **Data Storage**: Storing cleaned data in a SQLite database for further analysis.\n",
    "\n",
    "### Technologies Used\n",
    "- **Python** for scripting\n",
    "- **Pandas** for data manipulation\n",
    "- **SQLAlchemy** for database operations\n",
    "- **Matplotlib** for visualization\n",
    "\n",
    "### Data Pipeline Implementation\n",
    "The pipeline functions to fetch, clean, and store data from the specified sources. Here's an overview of the pipeline implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_directory = \"../data\"\n",
    "\n",
    "# Function to run the entire data pipeline\n",
    "def run_pipeline(data_url, table_name):\n",
    "    table = fetch_process_data(data_url)\n",
    "    save_to_sql(table, table_name)\n",
    "    return table\n",
    "\n",
    "# Function to fetch and process data\n",
    "def fetch_process_data(url):\n",
    "    try:\n",
    "        response = requests.get(url).content\n",
    "        dataframe = pd.read_csv(io.StringIO(response.decode('utf-8')))\n",
    "        dataframe = dataframe.dropna()  # Data cleaning step\n",
    "        return dataframe\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to save data to SQL database\n",
    "def save_to_sql(table, table_name):\n",
    "    if table is not None:\n",
    "        table_path = f\"{file_directory}/{table_name}.db\"\n",
    "        engine = create_engine(f'sqlite:///{table_path}')\n",
    "        table.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    else:\n",
    "        print(\"Error: Table is empty\")\n",
    "\n",
    "# Data sources with their respective URLs\n",
    "data_sources = {\n",
    "    \"surface_temperature\": \"https://opendata.arcgis.com/datasets/4063314923d74187be9596f10d034914_0.csv\",\n",
    "    \"land_cover\": \"https://opendata.arcgis.com/datasets/b1e6c0ea281f47b285addae0cbb28f4b_0.csv\"\n",
    "}\n",
    "\n",
    "dataframes = []\n",
    "# Running the data pipeline for each dataset\n",
    "for table_name, url in data_sources.items():\n",
    "    dataframes.append(run_pipeline(url, table_name))\n",
    "\n",
    "def plot_data(df, title, x_label, y_label, label, trim_index, output):\n",
    "    # Filter for specific countries\n",
    "    countries = ['Germany', 'France', 'Italy', 'Spain', 'United Kingdom', 'United States']\n",
    "    filtered_df = df[df['Country'].isin(countries)]\n",
    "\n",
    "    # Select the columns from the given trim_index onward for the years\n",
    "    year_columns = df.columns[trim_index:]\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    for country in countries:\n",
    "        country_data = filtered_df[filtered_df['Country'] == country]\n",
    "        if trim_index == 11:\n",
    "            country_data = country_data[country_data['Indicator'] == 'Climate Altering Land Cover Index']\n",
    "        yearly_data = country_data[year_columns].mean(axis=0)\n",
    "        plt.plot(yearly_data, label=f'{label} - {country}')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{output}_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "plot_data(dataframes[0], \"Annual Temperature from 1961 to 2022\", \"Year\", \"Temperature\", \"Annual Tempreature\", 10, \"temperature\")\n",
    "plot_data(dataframes[1], \"Land Cover from 1992 to 2018(Indicator: Climate Altering Land Cover Index)\", \"Year\", \"Land Cover\", \"Land Cover\", 11, \"land_cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion\n",
    "\n",
    "### Surface Temperature Analysis\n",
    "Surface temperature data for 1961-2021 indicate very well the continuous rate of increase of global temperatures, hence confirming global warming. This next figure clearly depicts it with annual temperature trends for some countries:\n",
    "This plot will clearly indicate the rise in temperatures for all regions considered here, hence evidencing a huge warming pattern over six decades. Insights on this kind of information are important to understand the full RAMifications of climate change globally.\n",
    "\n",
    "\n",
    "![Annual Temperature from 1961 to 2022](./temperature_plot.png)\n",
    "\n",
    "### Land Cover Analysis\n",
    "The dynamics of different land cover contributing toward carbon sequestration and climate regulation are portrayed by the 1992â€“2018 land cover data. Land cover dynamics is shown in the figure below for selected indicators:\n",
    "The plot highlights the dynamics of land cover types with effects on the indicators of climate change. Especially, the dynamics in forest cover and agricultural land use are key drivers associated with carbon sequestration. These findings help identify critical areas for policy intervention and land management practices to mitigate climate impacts.\n",
    "\n",
    "![Land Cover from 1992 to 2018](./land_cover_plot.png)\n",
    "\n",
    "### Limitations\n",
    "The datasets are limited to publicly available data and might not capture all geographical nuances, which could affect the granularity of the analysis.\n",
    "\n",
    "## Conclusions\n",
    "It evidences the critical role of automated data pipelines in processing and analyzing complex datasets. The insights derived from the Annual Surface Temperature and Land Cover data are very important for the policymakers to understand and mitigate the effects of climate change. This work has, despite these inadvertent findings, intrinsic limitations to the analysis based on data availability and coverage, thus indicating that the next lines of research require even more comprehensive sources of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
